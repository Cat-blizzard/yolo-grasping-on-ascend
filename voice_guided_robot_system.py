#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è§†è§‰å¼•å¯¼æœºæ¢°è‡‚æŠ“å–ç³»ç»Ÿ - ä¸»æ§ç¨‹åº
æ•´åˆ: è¯­éŸ³è¯†åˆ« â†’ LLMè¯­ä¹‰è§£æ â†’ YOLOv8è§†è§‰æ„ŸçŸ¥ â†’ ç›®æ ‡åŒ¹é… â†’ æœºæ¢°è‡‚æ‰§è¡Œ
"""

import os
import sys
import time
import json
import cv2
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import logging

# ==================== é…ç½®æ—¥å¿— ====================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# å¯¼å…¥æ·±åº¦å­¦ä¹ æ¡†æ¶ - ä¼˜å…ˆNPU,è‡ªåŠ¨é™çº§CPU
try:
    import mindspore as ms
    from mindspore import Tensor
    MINDSPORE_AVAILABLE = True
    logger.info("âœ… MindSporeå·²å®‰è£… (æ”¯æŒNPUæ¨ç†)")
except ImportError:
    MINDSPORE_AVAILABLE = False
    logger.warning("âš ï¸ MindSporeæœªå®‰è£…,å°†ä½¿ç”¨PyTorch (CPUæ¨¡å¼)")

try:
    import torch
    from torchvision import models, transforms
    TORCH_AVAILABLE = True
    logger.info("âœ… PyTorchå·²å®‰è£… (CPU/GPUå¤‡ç”¨)")
except ImportError:
    TORCH_AVAILABLE = False
    logger.warning("âš ï¸ PyTorchæœªå®‰è£…")

# å¯¼å…¥å­æ¨¡å—
sys.path.insert(0, str(Path(__file__).parent / "mindyolo-master" / "demo"))
sys.path.insert(0, str(Path(__file__).parent / "mindyolo-master"))

from mindyolo.models import create_model
from mindyolo.utils.config import parse_args
from mindyolo.utils.metrics import non_max_suppression, scale_coords, xyxy2xywh

# å¯¼å…¥æœ¬åœ°æ¨¡å— - demoåœ¨mindyolo-masteræ ¹ç›®å½•
import sys
import os
# æ·»åŠ demoç›®å½•åˆ°Pythonè·¯å¾„
demo_path = os.path.join(os.path.dirname(__file__), 'mindyolo-master', 'demo')
if demo_path not in sys.path:
    sys.path.insert(0, demo_path)

from recognize_voice import asr_recognize
from LLMæ„å›¾è¯†åˆ« import target_objects

# ROS2ç›¸å…³å¯¼å…¥
try:
    import rclpy
    from dofbot_info.srv import Kinemarics
    import Arm_Lib
    ROS2_AVAILABLE = True
    logger.info("âœ… ROS2æ¨¡å—å·²å®‰è£… (æ”¯æŒæœºæ¢°è‡‚æ§åˆ¶)")
except ImportError:
    ROS2_AVAILABLE = False
    logger.warning("âš ï¸ ROS2æ¨¡å—æœªå®‰è£…,æœºæ¢°è‡‚åŠŸèƒ½å°†è¢«ç¦ç”¨")


# ==================== COCOç±»åˆ«åç§° ====================
COCO_NAMES = [
    "person", "bicycle", "car", "motorcycle", "airplane", "bus", "train", "truck", "boat",
    "traffic light", "fire hydrant", "stop sign", "parking meter", "bench", "bird", "cat",
    "dog", "horse", "sheep", "cow", "elephant", "bear", "zebra", "giraffe", "backpack",
    "umbrella", "handbag", "tie", "suitcase", "frisbee", "skis", "snowboard", "sports ball",
    "kite", "baseball bat", "baseball glove", "skateboard", "surfboard", "tennis racket",
    "bottle", "wine glass", "cup", "fork", "knife", "spoon", "bowl", "banana", "apple",
    "sandwich", "orange", "broccoli", "carrot", "hot dog", "pizza", "donut", "cake", "chair",
    "couch", "potted plant", "bed", "dining table", "toilet", "tv", "laptop", "mouse",
    "remote", "keyboard", "cell phone", "microwave", "oven", "toaster", "sink", "refrigerator",
    "book", "clock", "vase", "scissors", "teddy bear", "hair drier", "toothbrush"
]


# ==================== ä¸­è‹±æ–‡ç‰©å“æ˜ å°„è¡¨ ====================
# ç›®æ ‡ç‰©å“: è‹¹æœã€æ©˜å­ã€æ¯å­ã€ç“¶å­
OBJECT_MAPPING = {
    "è‹¹æœ": "apple",
    "æ©˜å­": "orange",
    "æ©™å­": "orange",
    "æ¯å­": "cup",
    "æ°´æ¯": "cup",
    "ç“¶å­": "bottle",
}

# ==================== åˆ†æ‹£ä½ç½®é…ç½® ====================
# å®šä¹‰4ä¸ªåˆ†æ‹£åŒºåŸŸçš„æ”¾ç½®ä½ç½®(å…³èŠ‚è§’åº¦)
SORTING_POSITIONS = {
    "apple": [45, 50, 20, 60, 265],    # è‹¹æœ - ä½ç½®1(å·¦å‰)
    "orange": [27, 75, 0, 50, 265],    # æ©˜å­ - ä½ç½®2(å·¦å)
    "cup": [147, 75, 0, 50, 265],      # æ¯å­ - ä½ç½®3(å³å)
    "bottle": [133, 50, 20, 60, 265]   # ç“¶å­ - ä½ç½®4(å³å‰)
}


# ==================== è§†è§‰æ„ŸçŸ¥æ¨¡å— ====================
class VisionPerception:
    """è§†è§‰æ„ŸçŸ¥æ¨¡å— - ä¼˜å…ˆNPU,è‡ªåŠ¨é™çº§CPU"""
    
    def __init__(self, model_path_mindir: str = None, model_path_pt: str = None, 
                 config_path: str = None, img_size: int = 640, device: str = "auto"):
        """
        åˆå§‹åŒ–è§†è§‰æ„ŸçŸ¥æ¨¡å— - æ™ºèƒ½é€‰æ‹©æœ€ä¼˜æ¨ç†åç«¯
        
        Args:
            model_path_mindir: MindIRæ¨¡å‹è·¯å¾„(.mindir) - ç”¨äºNPU
            model_path_pt: PyTorchæ¨¡å‹è·¯å¾„(.pt) - ç”¨äºCPU/GPU
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            img_size: æ¨ç†å›¾åƒå°ºå¯¸
            device: è®¾å¤‡ç±»å‹("auto", "npu", "cpu", "cuda")
        """
        self.img_size = img_size
        self.conf_thres = 0.5  # ç½®ä¿¡åº¦é˜ˆå€¼
        self.iou_thres = 0.65   # NMS IoUé˜ˆå€¼
        self.use_mindspore = False
        self.use_torch = False
        self.backend_name = "Unknown"
        
        logger.info("="*60)
        logger.info("ğŸ”„ åˆå§‹åŒ–è§†è§‰æ„ŸçŸ¥æ¨¡å—")
        logger.info("="*60)
        
        # ç­–ç•¥: ä¼˜å…ˆNPU â†’ GPU â†’ CPU
        if device == "auto":
            device = self._auto_select_device()
        
        logger.info(f"ğŸ“ ç›®æ ‡è®¾å¤‡: {device}")
        
        # 1ï¸âƒ£ ä¼˜å…ˆå°è¯•NPU (MindSpore + æ˜‡è…¾310B)
        if device == "npu" and MINDSPORE_AVAILABLE:
            if self._try_load_npu(model_path_mindir, img_size):
                return
        
        # 2ï¸âƒ£ é™çº§: GPU (PyTorch + CUDA)
        if device == "cuda" and TORCH_AVAILABLE:
            if self._try_load_gpu(model_path_pt):
                return
        
        # 3ï¸âƒ£ æœ€åé™çº§: CPU (PyTorch)
        if TORCH_AVAILABLE:
            if self._try_load_cpu(model_path_pt):
                return
        
        # 4ï¸âƒ£ éƒ½å¤±è´¥åˆ™æŠ¥é”™
        raise RuntimeError(
            "âŒ æ— å¯ç”¨æ¨ç†åç«¯!\n"
            "è¯·å®‰è£…ä»¥ä¸‹ä¹‹ä¸€:\n"
            "  - NPU: pip install mindspore (éœ€æ˜‡è…¾é©±åŠ¨)\n"
            "  - CPU/GPU: pip install ultralytics torch"
        )
    
    def _auto_select_device(self) -> str:
        """è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜è®¾å¤‡"""
        # æ£€æµ‹NPU
        if MINDSPORE_AVAILABLE:
            try:
                import subprocess
                result = subprocess.run(['npu-smi', 'info'], 
                                       capture_output=True, timeout=2)
                if result.returncode == 0:
                    logger.info("âœ… æ£€æµ‹åˆ°æ˜‡è…¾NPU")
                    return "npu"
            except:
                pass
        
        # æ£€æµ‹GPU
        if TORCH_AVAILABLE:
            try:
                import torch
                if torch.cuda.is_available():
                    logger.info(f"âœ… æ£€æµ‹åˆ°CUDA GPU: {torch.cuda.get_device_name(0)}")
                    return "cuda"
            except:
                pass
        
        # é»˜è®¤CPU
        logger.info("â„¹ï¸ ä½¿ç”¨CPUæ¨¡å¼")
        return "cpu"
    
    def _try_load_npu(self, model_path: str, img_size: int) -> bool:
        """å°è¯•åŠ è½½NPUæ¨¡å‹"""
        try:
            logger.info("ğŸš€ å°è¯•åŠ è½½NPUæ¨¡å‹...")
            
            if not model_path or not os.path.exists(model_path):
                logger.warning(f"âš ï¸ NPUæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
                return False
            
            # è®¾ç½®Ascendä¸Šä¸‹æ–‡
            ms.set_context(mode=ms.GRAPH_MODE, device_target="Ascend", device_id=0)
            ms.set_recursion_limit(2000)
            
            # åŠ è½½MindIRæ¨¡å‹
            graph = ms.load_mindir(model_path)
            self.network = ms.nn.GraphCell(graph)
            
            # é¢„çƒ­ç¼–è¯‘
            dummy = Tensor(np.ones((1, 3, img_size, img_size)), ms.float32)
            _ = self.network(dummy)
            
            self.use_mindspore = True
            self.backend_name = "NPU (Ascend 310B)"
            logger.info("âœ… NPUæ¨¡å‹åŠ è½½æˆåŠŸ! (æ˜‡è…¾310B)")
            logger.info(f"   æ¨¡å‹è·¯å¾„: {model_path}")
            logger.info(f"   é¢„æœŸæ¨ç†é€Ÿåº¦: ~30ms/å¸§")
            return True
            
        except Exception as e:
            logger.warning(f"âš ï¸ NPUåŠ è½½å¤±è´¥: {e}")
            logger.info("   å°†å°è¯•é™çº§åˆ°CPUæ¨¡å¼...")
            return False
    
    def _try_load_gpu(self, model_path: str) -> bool:
        """å°è¯•åŠ è½½GPUæ¨¡å‹"""
        try:
            logger.info("ğŸš€ å°è¯•åŠ è½½GPUæ¨¡å‹...")
            from ultralytics import YOLO
            import torch
            
            if not torch.cuda.is_available():
                logger.warning("âš ï¸ CUDAä¸å¯ç”¨")
                return False
            
            # åŠ è½½YOLOv8æ¨¡å‹
            if model_path and os.path.exists(model_path):
                self.model = YOLO(model_path)
            else:
                logger.info("   ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ (è‡ªåŠ¨ä¸‹è½½yolov8s.pt)")
                self.model = YOLO('yolov8s.pt')
            
            self.model.to('cuda')
            
            self.use_torch = True
            self.backend_name = f"GPU ({torch.cuda.get_device_name(0)})"
            logger.info("âœ… GPUæ¨¡å‹åŠ è½½æˆåŠŸ!")
            logger.info(f"   é¢„æœŸæ¨ç†é€Ÿåº¦: ~20-50ms/å¸§")
            return True
            
        except Exception as e:
            logger.warning(f"âš ï¸ GPUåŠ è½½å¤±è´¥: {e}")
            return False
    
    def _try_load_cpu(self, model_path: str) -> bool:
        """å°è¯•åŠ è½½CPUæ¨¡å‹"""
        try:
            logger.info("ğŸš€ åŠ è½½CPUæ¨¡å‹...")
            from ultralytics import YOLO
            
            # åŠ è½½YOLOv8æ¨¡å‹
            if model_path and os.path.exists(model_path):
                self.model = YOLO(model_path)
            else:
                logger.info("   ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ (è‡ªåŠ¨ä¸‹è½½yolov8s.pt)")
                self.model = YOLO('yolov8s.pt')
            
            self.model.to('cpu')
            
            self.use_torch = True
            self.backend_name = "CPU"
            logger.info("âœ… CPUæ¨¡å‹åŠ è½½æˆåŠŸ!")
            logger.info("   é¢„æœŸæ¨ç†é€Ÿåº¦: ~100-200ms/å¸§")
            return True
            
        except Exception as e:
            logger.error(f"âŒ CPUåŠ è½½å¤±è´¥: {e}")
            return False
    
    def detect(self, img: np.ndarray) -> Dict:
        """æ‰§è¡Œç›®æ ‡æ£€æµ‹ - è‡ªåŠ¨é€‰æ‹©åç«¯"""
        if self.use_torch:
            return self._detect_torch(img)
        elif self.use_mindspore:
            return self._detect_mindspore(img)
        else:
            raise RuntimeError("æ— å¯ç”¨æ£€æµ‹åç«¯")
    
    def _detect_torch(self, img: np.ndarray) -> Dict:
        """
        PyTorch/Ultralytics YOLOæ£€æµ‹
        
        Args:
            img: BGRæ ¼å¼çš„è¾“å…¥å›¾åƒ
            
        Returns:
            æ£€æµ‹ç»“æœå­—å…¸
        """
        t0 = time.time()
        
        # Ultralytics YOLOæ¨ç†
        results = self.model(img, conf=self.conf_thres, iou=self.iou_thres, verbose=False)
        result = results[0]  # ç¬¬ä¸€å¼ å›¾
        
        infer_time = time.time() - t0
        logger.info(f"â±ï¸ æ¨ç†è€—æ—¶: {infer_time*1000:.1f}ms ({self.backend_name})")
        
        # è§£æç»“æœ
        detections = []
        boxes = result.boxes
        
        for box in boxes:
            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
            conf = float(box.conf[0])
            cls_id = int(box.cls[0])
            
            # è®¡ç®—ä¸­å¿ƒç‚¹
            cx = int((x1 + x2) / 2)
            cy = int((y1 + y2) / 2)
            
            detections.append({
                "class_id": cls_id,
                "class_name": COCO_NAMES[cls_id] if cls_id < len(COCO_NAMES) else "unknown",
                "confidence": conf,
                "bbox": [float(x1), float(y1), float(x2), float(y2)],
                "center": (cx, cy)
            })
        
        logger.info(f"ğŸ‘ï¸ æ£€æµ‹åˆ° {len(detections)} ä¸ªç‰©ä½“")
        return {"detections": detections}
    
    def _detect_mindspore(self, img: np.ndarray) -> Dict:
        """
        MindSporeæ£€æµ‹(å¤‡ç”¨)
        
        Args:
            img: BGRæ ¼å¼çš„è¾“å…¥å›¾åƒ
            
        Returns:
            æ£€æµ‹ç»“æœå­—å…¸
        """
        h_ori, w_ori = img.shape[:2]
        # 1. å›¾åƒé¢„å¤„ç†
        r = self.img_size / max(h_ori, w_ori)
        if r != 1:
            interp = cv2.INTER_AREA if r < 1 else cv2.INTER_LINEAR
            img_resized = cv2.resize(img, (int(w_ori * r), int(h_ori * r)), interpolation=interp)
        else:
            img_resized = img.copy()
        
        # Paddingåˆ°640x640
        h, w = img_resized.shape[:2]
        if h < self.img_size or w < self.img_size:
            dh = (self.img_size - h) / 2
            dw = (self.img_size - w) / 2
            img_resized = cv2.copyMakeBorder(
                img_resized, int(dh), int(dh), int(dw), int(dw),
                cv2.BORDER_CONSTANT, value=(114, 114, 114)
            )
        
        # è½¬æ¢ä¸ºTensor (NCHW, RGB, [0,1])
        img_tensor = img_resized[:, :, ::-1].transpose(2, 0, 1) / 255.0
        img_tensor = Tensor(img_tensor[None], ms.float32)
        
        # 2. NPUæ¨ç†
        t0 = time.time()
        out = self.network(img_tensor)
        infer_time = time.time() - t0
        
        # 3. NMSåå¤„ç†
        out = out.asnumpy()
        t1 = time.time()
        out = non_max_suppression(out, conf_thres=self.conf_thres, iou_thres=self.iou_thres, need_nms=True)
        nms_time = time.time() - t1
        
        logger.info(f"â±ï¸ æ¨ç†è€—æ—¶: {infer_time*1000:.1f}ms | NMS: {nms_time*1000:.1f}ms")
        
        # 4. è§£æç»“æœ
        detections = []
        for pred in out:
            if len(pred) == 0:
                continue
            
            # åæ ‡æ˜ å°„å›åŸå›¾
            predn = np.copy(pred)
            scale_coords(img_tensor.shape[2:], predn[:, :4], (h_ori, w_ori))
            
            for det in predn:
                x1, y1, x2, y2, conf, cls_id = det
                cls_id = int(cls_id)
                
                # è®¡ç®—ä¸­å¿ƒç‚¹
                cx = int((x1 + x2) / 2)
                cy = int((y1 + y2) / 2)
                
                detections.append({
                    "class_id": cls_id,
                    "class_name": COCO_NAMES[cls_id] if cls_id < len(COCO_NAMES) else "unknown",
                    "confidence": float(conf),
                    "bbox": [float(x1), float(y1), float(x2), float(y2)],
                    "center": (cx, cy)
                })
        
        logger.info(f"ğŸ‘ï¸ æ£€æµ‹åˆ° {len(detections)} ä¸ªç‰©ä½“")
        return {"detections": detections}


# ==================== å†³ç­–å±‚æ¨¡å— ====================
class DecisionLayer:
    """å†³ç­–å±‚ - è´Ÿè´£ç›®æ ‡åŒ¹é…å’Œä»»åŠ¡ç”Ÿæˆ"""
    
    @staticmethod
    def match_target(voice_target: str, visual_detections: List[Dict]) -> Optional[Dict]:
        """
        åŒ¹é…è¯­éŸ³ç›®æ ‡ä¸è§†è§‰æ£€æµ‹ç»“æœ
        
        Args:
            voice_target: è¯­éŸ³æå–çš„ä¸­æ–‡ç›®æ ‡(å¦‚"æ°´æ¯")
            visual_detections: è§†è§‰æ£€æµ‹ç»“æœåˆ—è¡¨
            
        Returns:
            åŒ¹é…æˆåŠŸè¿”å›æœ€ä½³ç›®æ ‡,å¤±è´¥è¿”å›None
        """
        # 1. ä¸­è‹±æ–‡æ˜ å°„
        english_target = OBJECT_MAPPING.get(voice_target)
        if not english_target:
            logger.warning(f"âš ï¸ æœªæ‰¾åˆ°'{voice_target}'çš„è‹±æ–‡æ˜ å°„")
            return None
        
        logger.info(f"ğŸ” åŒ¹é…ç›®æ ‡: {voice_target} â†’ {english_target}")
        
        # 2. åœ¨æ£€æµ‹ç»“æœä¸­æŸ¥æ‰¾
        candidates = [
            det for det in visual_detections 
            if det["class_name"] == english_target
        ]
        
        if not candidates:
            logger.warning(f"âŒ æœªæ£€æµ‹åˆ°ç›®æ ‡ç‰©ä½“: {english_target}")
            return None
        
        # 3. é€‰æ‹©æœ€é«˜ç½®ä¿¡åº¦çš„ç›®æ ‡
        best_match = max(candidates, key=lambda x: x["confidence"])
        logger.info(f"âœ… åŒ¹é…æˆåŠŸ: {best_match['class_name']} (ç½®ä¿¡åº¦: {best_match['confidence']:.2%})")
        
        return best_match


# ==================== åæ ‡æ˜ å°„æ¨¡å— ====================
class CoordinateMapper:
    """åæ ‡æ˜ å°„æ¨¡å— - åƒç´ åæ ‡è½¬æœºæ¢°è‡‚åŸºåæ ‡"""
    
    def __init__(self, offset_path: str, dp_bin_path: Optional[str] = None):
        """
        åˆå§‹åŒ–åæ ‡æ˜ å°„
        
        Args:
            offset_path: offset.txtæ–‡ä»¶è·¯å¾„
            dp_bin_path: é€è§†å˜æ¢å‚æ•°æ–‡ä»¶è·¯å¾„(å¯é€‰)
        """
        # è¯»å–åç§»é‡
        with open(offset_path, 'r') as f:
            self.y_offset = float(f.readline().strip())
            self.x_offset = float(f.readline().strip())
        
        logger.info(f"ğŸ“ åæ ‡åç§»: x={self.x_offset}, y={self.y_offset}")
        
        self.dp_bin_path = dp_bin_path
    
    def pixel_to_robot_base(self, pixel_x: int, pixel_y: int, img_width: int = 640, img_height: int = 480) -> Tuple[float, float]:
        """
        åƒç´ åæ ‡è½¬æœºæ¢°è‡‚åŸºåæ ‡
        
        Args:
            pixel_x, pixel_y: åƒç´ åæ ‡
            img_width, img_height: å›¾åƒå°ºå¯¸
            
        Returns:
            (x, y) æœºæ¢°è‡‚åŸºåæ ‡ç³»ä¸‹çš„åæ ‡
        """
        # å‚è€ƒgarbage_identify.pyçš„è½¬æ¢å…¬å¼
        a = round(((pixel_x - 320) / 4000), 5)
        b = round(((480 - pixel_y) / 3000) * 0.8 + 0.19, 5)
        
        # åº”ç”¨åç§»è¡¥å¿
        x = a + self.x_offset
        y = b + self.y_offset
        
        logger.info(f"ğŸ“ åæ ‡æ˜ å°„: åƒç´ ({pixel_x}, {pixel_y}) â†’ æœºæ¢°è‡‚({x:.4f}, {y:.4f})")
        return (x, y)


# ==================== æœºæ¢°è‡‚æ‰§è¡Œæ¨¡å— ====================
class RobotArmController:
    """æœºæ¢°è‡‚æ‰§è¡Œæ¨¡å— - ROS2æœåŠ¡è°ƒç”¨ + é€†è¿åŠ¨å­¦"""
    
    def __init__(self):
        """åˆå§‹åŒ–æœºæ¢°è‡‚æ§åˆ¶å™¨"""
        logger.info("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–æœºæ¢°è‡‚æ§åˆ¶å™¨...")
        
        if not ROS2_AVAILABLE:
            logger.error("âŒ ROS2ä¸å¯ç”¨,æœºæ¢°è‡‚æ§åˆ¶å™¨åˆå§‹åŒ–å¤±è´¥")
            logger.info("ğŸ’¡ è¯·æ£€æŸ¥: pip3 install rclpy Arm_Lib")
            self.node = None
            self.client = None
            self.arm = None
            return
        
        try:
            # æ£€æŸ¥ROS2æ˜¯å¦å·²åˆå§‹åŒ–(å‚è€ƒgarbage_identify.py line 30)
            if not rclpy.ok():
                rclpy.init()
                logger.info("ğŸ”§ ROS2åˆå§‹åŒ–å®Œæˆ")
            
            self.node = rclpy.create_node("voice_robot_controller")
            logger.info("âœ… ROS2èŠ‚ç‚¹åˆ›å»ºæˆåŠŸ")
            
            self.client = self.node.create_client(Kinemarics, "trial_service")
            logger.info("âœ… é€†è¿åŠ¨å­¦æœåŠ¡å®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸ")
            
            self.arm = Arm_Lib.Arm_Device()
            logger.info("âœ… æœºæ¢°è‡‚è®¾å¤‡è¿æ¥æˆåŠŸ")
            
            logger.info("âœ… æœºæ¢°è‡‚æ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            logger.error(f"âŒ æœºæ¢°è‡‚åˆå§‹åŒ–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            self.node = None
            self.client = None
            self.arm = None
    
    def inverse_kinematics(self, x: float, y: float, z: float = 0.0) -> List[float]:
        """
        è°ƒç”¨ROS2é€†è¿åŠ¨å­¦æœåŠ¡
        
        Args:
            x, y, z: ç›®æ ‡ä½å§¿(åŸºåæ ‡ç³»)
            
        Returns:
            å…³èŠ‚è§’åº¦åˆ—è¡¨ [j1, j2, j3, j4, j5]
        """
        if not ROS2_AVAILABLE or not self.client:
            logger.warning("âš ï¸ ROS2ä¸å¯ç”¨,è¿”å›é»˜è®¤å…³èŠ‚è§’")
            return None
        
        try:
            logger.info(f"ğŸ”§ [æ­¥éª¤6.1] ç­‰å¾…é€†è¿åŠ¨å­¦æœåŠ¡ 'trial_service'...")
            logger.info(f"   ç›®æ ‡åæ ‡: x={x:.4f}, y={y:.4f}, z={z:.4f}")
            
            service_ready = self.client.wait_for_service(timeout_sec=5.0)
            if not service_ready:
                logger.error("âŒ [å¤±è´¥] é€†è¿åŠ¨å­¦æœåŠ¡è¶…æ—¶(5ç§’å†…æœªå“åº”)")
                logger.error("ğŸ’¡ è°ƒè¯•æ­¥éª¤:")
                logger.error("   1. æ£€æŸ¥ROS2æœåŠ¡: ros2 service list | grep trial_service")
                logger.error("   2. æ£€æŸ¥ROS2ç¯å¢ƒ: echo $ROS_DOMAIN_ID")
                logger.error("   3. é‡å¯æœåŠ¡: ros2 run dofbot_info kinemarics_server")
                return None
            
            logger.info("âœ… [æ­¥éª¤6.2] é€†è¿åŠ¨å­¦æœåŠ¡å·²å°±ç»ª")
            
            request = Kinemarics.Request()
            request.tar_x = x
            request.tar_y = y
            request.tar_z = z
            request.kin_name = "ik"
            
            logger.info(f"ğŸ“ [æ­¥éª¤6.3] å‘é€é€†è¿åŠ¨å­¦è¯·æ±‚: ({x:.3f}, {y:.3f}, {z:.3f})")
            logger.info(f"   ç­‰å¾…æœåŠ¡å“åº”(æœ€å¤š5ç§’)...")
            
            future = self.client.call_async(request)
            rclpy.spin_until_future_complete(self.node, future, timeout_sec=5.0)
            
            if not future.done():
                logger.error("âŒ [æ­¥éª¤6.4] æœåŠ¡è°ƒç”¨è¶…æ—¶(æœªåœ¨5ç§’å†…å®Œæˆ)")
                logger.error("ğŸ’¡ å¯èƒ½åŸå› :")
                logger.error("   - ç›®æ ‡åæ ‡è¶…å‡ºæœºæ¢°è‡‚å·¥ä½œç©ºé—´")
                logger.error("   - é€†è¿åŠ¨å­¦æ±‚è§£å™¨å¡æ­»")
                logger.error("   - ROS2ç½‘ç»œé€šä¿¡å¼‚å¸¸")
                return None
            
            logger.info("âœ… [æ­¥éª¤6.4] æœåŠ¡è°ƒç”¨å®Œæˆ,è·å–å“åº”...")
            response = future.result()
            
            if response:
                joints = [
                    response.joint1,
                    response.joint2,
                    response.joint3,
                    response.joint4,
                    response.joint5
                ]
                
                logger.info(f"ğŸ“Š [æ­¥éª¤6.5] åŸå§‹å…³èŠ‚è§’: {joints}")
                
                # è§’åº¦è°ƒæ•´(å‚è€ƒgarbage_identify.py)
                if joints[2] < 0:
                    logger.info(f"âš™ï¸ å…³èŠ‚è§’è°ƒæ•´: joint3={joints[2]} < 0, åº”ç”¨è¡¥å¿")
                    joints[1] += joints[2] / 2
                    joints[3] += joints[2] * 3 / 4
                    joints[2] = 0
                
                logger.info(f"âœ… [æ­¥éª¤6.6] é€†è¿åŠ¨å­¦è§£ç®—æˆåŠŸ: ({x:.3f}, {y:.3f}, {z:.3f}) â†’ {joints}")
                return joints
            else:
                logger.error("âŒ [å¤±è´¥] é€†è¿åŠ¨å­¦æœåŠ¡è¿”å›ç©ºå“åº”")
                logger.error("ğŸ’¡ è¯·æ£€æŸ¥ROS2æœåŠ¡å®ç°æ˜¯å¦æ­£å¸¸")
                return None
        except Exception as e:
            logger.error(f"âŒ [å¼‚å¸¸] é€†è¿åŠ¨å­¦è°ƒç”¨å¤±è´¥: {e}")
            logger.error("ğŸ’¡ å¼‚å¸¸è¯¦æƒ…:")
            import traceback
            traceback.print_exc()
            return None
    
    def grasp_and_place(self, joints: List[float], target_class: str, xy_init: List[int] = [90, 135]):
        """
        æ‰§è¡ŒæŠ“å–+åˆ†æ‹£åŠ¨ä½œ
        
        Args:
            joints: ç›®æ ‡å…³èŠ‚è§’åº¦
            target_class: ç›®æ ‡ç±»åˆ«("apple", "orange", "cup", "bottle")
            xy_init: åˆå§‹ä½ç½®
        """
        if not ROS2_AVAILABLE:
            logger.warning("âš ï¸ ROS2ä¸å¯ç”¨,è·³è¿‡æœºæ¢°è‡‚åŠ¨ä½œ")
            return
        
        if not self.arm:
            logger.error("âŒ æœºæ¢°è‡‚è®¾å¤‡æœªåˆå§‹åŒ–,æ— æ³•æ‰§è¡ŒåŠ¨ä½œ")
            return
        
        logger.info(f"ğŸ¤– [æ­¥éª¤6.7] å¼€å§‹æ‰§è¡ŒæŠ“å–åŠ¨ä½œ: {target_class}")
        logger.info(f"   ç›®æ ‡å…³èŠ‚è§’: {joints}")
        
        try:
            # èœ‚é¸£å™¨æç¤º
            logger.info("ğŸ”” [åŠ¨ä½œ1] èœ‚é¸£å™¨æç¤º...")
            self.arm.Arm_Buzzer_On(1)
            time.sleep(0.5)
        
            grap_joint = 130  # å¤¹çˆªé—­åˆè§’åº¦
            
            # 1. ç§»åŠ¨åˆ°ç›®æ ‡ä¸Šæ–¹
            joints_up = [joints[0], 80, 50, 50, 265, 30]
            logger.info(f"ğŸ“ [åŠ¨ä½œ2] ç§»åŠ¨åˆ°ç›®æ ‡ä¸Šæ–¹: {joints_up}")
            self.arm.Arm_serial_servo_write6_array(joints_up, 1000)
            time.sleep(1)
            
            # 2. æ¾å¼€å¤¹çˆª
            logger.info("âœ‹ [åŠ¨ä½œ3] æ¾å¼€å¤¹çˆª...")
            self.arm.Arm_serial_servo_write(6, 0, 500)
            time.sleep(0.5)
            
            # 3. ç§»åŠ¨åˆ°ç›®æ ‡ä½ç½®
            joints_target = [joints[0], joints[1], joints[2], joints[3], 265, 30]
            logger.info(f"ğŸ¯ [åŠ¨ä½œ4] ç§»åŠ¨åˆ°æŠ“å–ä½ç½®: {joints_target}")
            self.arm.Arm_serial_servo_write6_array(joints_target, 500)
            time.sleep(0.5)
            
            # 4. å¤¹ç´§
            logger.info(f"ğŸ¤ [åŠ¨ä½œ5] å¤¹çˆªé—­åˆ(è§’åº¦={grap_joint})...")
            self.arm.Arm_serial_servo_write(6, grap_joint, 500)
            time.sleep(0.5)
            
            # 5. æŠ¬èµ·
            logger.info("â¬†ï¸ [åŠ¨ä½œ6] æŠ¬èµ·ç‰©ä½“...")
            self.arm.Arm_serial_servo_write6_array(joints_up, 1000)
            time.sleep(1)
            
            # 6. ç§»åŠ¨åˆ°åˆ†æ‹£ä½ç½®
            if target_class in SORTING_POSITIONS:
                sorting_joints = SORTING_POSITIONS[target_class] + [grap_joint]
                logger.info(f"ğŸ“¦ [åŠ¨ä½œ7] ç§»åŠ¨åˆ°åˆ†æ‹£ä½ç½®: {target_class} â†’ {sorting_joints}")
                self.arm.Arm_serial_servo_write6_array(sorting_joints, 1000)
                time.sleep(1)
                
                # 7. é‡Šæ”¾ç‰©ä½“
                logger.info("ğŸ [åŠ¨ä½œ8] é‡Šæ”¾ç‰©ä½“...")
                self.arm.Arm_serial_servo_write(6, 30, 500)
                time.sleep(0.5)
            else:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°{target_class}çš„åˆ†æ‹£ä½ç½®,æ”¾å›åˆå§‹ä½ç½®")
            
            # 8. è¿”å›åˆå§‹ä½ç½®
            joints_init = [xy_init[0], xy_init[1], 0, 0, 90, 30]
            logger.info(f"ğŸ”™ [åŠ¨ä½œ9] è¿”å›åˆå§‹ä½ç½®: {joints_init}")
            self.arm.Arm_serial_servo_write6_array(joints_init, 1000)
            time.sleep(1)
            
            logger.info("âœ… [æ­¥éª¤6å®Œæˆ] æŠ“å–åŠ¨ä½œæ‰§è¡ŒæˆåŠŸ")
            
        except Exception as e:
            logger.error(f"âŒ [æœºæ¢°è‡‚åŠ¨ä½œå¼‚å¸¸] {e}")
            import traceback
            traceback.print_exc()
            raise


# ==================== ä¸»ç³»ç»Ÿ ====================
class VoiceGuidedRobotSystem:
    """è¯­éŸ³å¼•å¯¼æœºæ¢°è‡‚ç³»ç»Ÿ - ä¸»æ§ç±»"""
    
    def __init__(self, config: Dict):
        """
        åˆå§‹åŒ–ç³»ç»Ÿ
        
        Args:
            config: é…ç½®å­—å…¸ {
                "model_path": YOLOv8æ¨¡å‹è·¯å¾„,
                "offset_path": offset.txtè·¯å¾„,
                "camera_id": æ‘„åƒå¤´ID
            }
        """
        logger.info("="*60)
        logger.info("ğŸš€ å¯åŠ¨è§†è§‰å¼•å¯¼æœºæ¢°è‡‚æŠ“å–ç³»ç»Ÿ")
        logger.info("="*60)
        
        # 1. åˆå§‹åŒ–è§†è§‰æ¨¡å— - ä¼˜å…ˆNPU
        model_path_mindir = config.get("model_path_mindir")  # NPUæ¨¡å‹
        model_path_pt = config.get("model_path_pt")  # CPU/GPUæ¨¡å‹
        device = config.get("device", "auto")  # auto/npu/cpu/cuda
        
        self.vision = VisionPerception(
            model_path_mindir=model_path_mindir,
            model_path_pt=model_path_pt,
            config_path=None,
            img_size=640,
            device=device
        )
        
        # 2. åˆå§‹åŒ–åæ ‡æ˜ å°„
        self.mapper = CoordinateMapper(offset_path=config["offset_path"])
        
        # 3. åˆå§‹åŒ–æœºæ¢°è‡‚æ§åˆ¶å™¨
        self.robot = RobotArmController() if ROS2_AVAILABLE else None
        
        # 4. æ‰“å¼€æ‘„åƒå¤´
        self.camera_id = config.get("camera_id", 0)
        self.cap = cv2.VideoCapture(self.camera_id)
        if not self.cap.isOpened():
            raise RuntimeError(f"âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {self.camera_id}")
        
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        self.cap.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'))
        
        logger.info("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def run_once(self, enable_voice=True, enable_llm=True):
        """æ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„æŠ“å–æµç¨‹"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ™ï¸ æ­¥éª¤1: è¯­éŸ³è¾“å…¥")
        logger.info("="*60)
        
        voice_text = ""
        target_name = ""
        
        # 1. è¯­éŸ³è¯†åˆ«(å¯é€‰)
        if enable_voice:
            print("\nâ–¶ï¸ è¯·è¯´å‡ºæ‚¨çš„æŒ‡ä»¤(å¦‚: å¸®æˆ‘æ‹¿è‹¹æœ)...")
            try:
                voice_text = asr_recognize(max_duration=5.0, interval_sec=0.04)
                logger.info(f"ğŸ“ è¯†åˆ«ç»“æœ: {voice_text}")
            except Exception as e:
                logger.error(f"âŒ è¯­éŸ³è¯†åˆ«å¤±è´¥: {e}")
                enable_llm = False
        
        # 2. LLMè¯­ä¹‰è§£æ(å¯é€‰)
        if enable_llm and voice_text:
            logger.info("\n" + "="*60)
            logger.info("ğŸ§  æ­¥éª¤2: è¯­ä¹‰è§£æ")
            logger.info("="*60)
            
            try:
                target_list = target_objects(voice_text)
                if not target_list:
                    logger.warning("âš ï¸ æœªè¯†åˆ«åˆ°ç›®æ ‡ç‰©å“")
                    return False
                
                target_name = target_list[0]  # å–ç¬¬ä¸€ä¸ªç›®æ ‡
                logger.info(f"ğŸ¯ æå–ç›®æ ‡: {target_name}")
            except Exception as e:
                logger.error(f"âŒ è¯­ä¹‰è§£æå¤±è´¥: {e}")
                return False
        
        # å¦‚æœæ²¡æœ‰è¯­éŸ³è¾“å…¥,ç›´æ¥æ£€æµ‹æ‰€æœ‰4ä¸ªç±»åˆ«
        if not target_name:
            logger.info("â„¹ï¸ æ— è¯­éŸ³è¾“å…¥,å°†æ£€æµ‹æ‰€æœ‰ç›®æ ‡ç±»åˆ«: è‹¹æœ/æ©˜å­/æ¯å­/ç“¶å­")
        
        # 3. è§†è§‰æ„ŸçŸ¥
        logger.info("\n" + "="*60)
        logger.info("ğŸ‘ï¸ æ­¥éª¤3: è§†è§‰æ„ŸçŸ¥")
        logger.info("="*60)
        
        ret, frame = self.cap.read()
        if not ret:
            logger.error("âŒ æ‘„åƒå¤´è¯»å–å¤±è´¥")
            return False
        
        # è°ƒæ•´å›¾åƒå°ºå¯¸
        frame = cv2.resize(frame, (640, 480))
        
        # æ‰§è¡Œæ£€æµ‹
        result = self.vision.detect(frame)
        detections = result["detections"]
        
        # å¯è§†åŒ–
        vis_img = frame.copy()
        for det in detections:
            x1, y1, x2, y2 = [int(v) for v in det["bbox"]]
            cv2.rectangle(vis_img, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(vis_img, f"{det['class_name']} {det['confidence']:.2f}", 
                       (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            cx, cy = det["center"]
            cv2.circle(vis_img, (cx, cy), 5, (0, 0, 255), -1)
        
        # ä¿å­˜æ£€æµ‹ç»“æœå›¾ç‰‡(é¿å…åœ¨æ— GUIç¯å¢ƒæ˜¾ç¤º)
        output_path = "detection_result.jpg"
        cv2.imwrite(output_path, vis_img)
        logger.info(f"ğŸ’¾ æ£€æµ‹ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
        # cv2.imshow("Detection Result", vis_img)  # åœ¨æ— GUIç¯å¢ƒä¸‹ç¦ç”¨
        # cv2.waitKey(2000)
        
        # 4. ç›®æ ‡åŒ¹é…
        logger.info("\n" + "="*60)
        logger.info("ğŸ” æ­¥éª¤4: ç›®æ ‡åŒ¹é…")
        logger.info("="*60)
        
        matched_target = DecisionLayer.match_target(target_name, detections)
        if not matched_target:
            logger.warning(f"âŒ æœªæ‰¾åˆ°ç›®æ ‡ç‰©ä½“: {target_name}")
            return False
        
        # 5. åæ ‡æ˜ å°„
        logger.info("\n" + "="*60)
        logger.info("ğŸ“ æ­¥éª¤5: åæ ‡æ˜ å°„")
        logger.info("="*60)
        
        cx, cy = matched_target["center"]
        robot_x, robot_y = self.mapper.pixel_to_robot_base(cx, cy)
        
        # 6. é€†è¿åŠ¨å­¦+æ‰§è¡Œ
        logger.info("\n" + "="*60)
        logger.info("ğŸ¤– æ­¥éª¤6: æœºæ¢°è‡‚æ‰§è¡Œ (å¦‚æœæ­¤å¤„å¡ä½,è¯·æŸ¥çœ‹ä¸‹æ–¹è¯¦ç»†æ—¥å¿—)")
        logger.info("="*60)
        
        if self.robot:
            logger.info(f"ğŸ“ ç›®æ ‡åæ ‡: ({robot_x:.4f}, {robot_y:.4f})")
            logger.info("ğŸ”§ å¼€å§‹è°ƒç”¨é€†è¿åŠ¨å­¦æ±‚è§£(ROS2æœåŠ¡)...")
            logger.info("ğŸ’¡ å¦‚æœé•¿æ—¶é—´æ— å“åº”,è¯·æ£€æŸ¥:")
            logger.info("   1. ROS2æœåŠ¡æ˜¯å¦è¿è¡Œ: ros2 service list")
            logger.info("   2. æœºæ¢°è‡‚ä¸²å£è¿æ¥: ls /dev/ttyUSB*")
            logger.info("   3. ç›®æ ‡åæ ‡æ˜¯å¦åœ¨å·¥ä½œç©ºé—´å†…")
            logger.info("\nå¼€å§‹æ‰§è¡Œ...\n")
            
            joints = self.robot.inverse_kinematics(robot_x, robot_y, z=0.0)
            if joints:
                logger.info(f"âœ… é€†è¿åŠ¨å­¦æ±‚è§£æˆåŠŸ: {joints}")
                
                # ä¼ é€’target_classè¿›è¡Œåˆ†æ‹£
                english_target = OBJECT_MAPPING.get(target_name, matched_target["class_name"])
                logger.info(f"ğŸ¯ å¼€å§‹æŠ“å–: {target_name} ({english_target})")
                
                try:
                    self.robot.grasp_and_place(joints, target_class=english_target)
                    logger.info("âœ… ä»»åŠ¡å®Œæˆ!")
                    return True
                except Exception as e:
                    logger.error(f"âŒ æœºæ¢°è‡‚æ‰§è¡Œå¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
                    return False
            else:
                logger.error("âŒ é€†è¿åŠ¨å­¦æ±‚è§£å¤±è´¥,å…³èŠ‚è§’åº¦ä¸ºNone")
                logger.info(f"ğŸ’¡ æç¤º: ç›®æ ‡åæ ‡({robot_x:.4f}, {robot_y:.4f})å¯èƒ½è¶…å‡ºæœºæ¢°è‡‚å·¥ä½œç©ºé—´")
                return False
        else:
            logger.warning("âš ï¸ æœºæ¢°è‡‚ä¸å¯ç”¨ (ROS2æœªå®‰è£…æˆ–åˆå§‹åŒ–å¤±è´¥)")
            logger.info(f"ğŸ“ ç›®æ ‡åæ ‡: ({robot_x:.4f}, {robot_y:.4f})")
            logger.info("ğŸ’¡ æç¤º: è¯·æ£€æŸ¥ROS2ç¯å¢ƒå’Œæœºæ¢°è‡‚è¿æ¥")
        
        return True
    
    def run_continuous(self):
        """æŒç»­è¿è¡Œæ¨¡å¼"""
        logger.info("\nğŸ” è¿›å…¥æŒç»­è¿è¡Œæ¨¡å¼ (æŒ‰Ctrl+Cé€€å‡º)")
        
        try:
            while True:
                self.run_once()
                logger.info("\nâ³ ç­‰å¾…5ç§’åæ‰§è¡Œä¸‹ä¸€æ¬¡...")
                time.sleep(5)
        except KeyboardInterrupt:
            logger.info("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­,ç³»ç»Ÿé€€å‡º")
        finally:
            self.cleanup()
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.cap:
            self.cap.release()
        cv2.destroyAllWindows()
        logger.info("â™»ï¸ èµ„æºå·²é‡Šæ”¾")


# ==================== ä¸»å…¥å£ ====================
def main():
    # é…ç½®å‚æ•° - ä¼˜å…ˆNPU,è‡ªåŠ¨é™çº§CPU
    import platform
    
    # åŸºç¡€é…ç½®
    config = {
        "model_path_mindir": None,  # NPUæ¨¡å‹(.mindir)
        "model_path_pt": None,      # CPU/GPUæ¨¡å‹(.pt)
        "offset_path": "",
        "camera_id": 0,
        "device": "auto"  # auto: è‡ªåŠ¨é€‰æ‹©(NPU>GPU>CPU)
    }
    
    # æ ¹æ®æ“ä½œç³»ç»Ÿè®¾ç½®è·¯å¾„
    if platform.system() == "Windows":
        # Windowsç¯å¢ƒ - æ”¯æŒNPU/CPU
        config["model_path_mindir"] = r"d:\robocode\mindyolo-master\yolov8s_coco.mindir"  # NPUæ¨¡å‹
        config["model_path_pt"] = r"d:\robocode\mindyolo-master\yolov8s.pt"  # CPUå¤‡ç”¨
        config["offset_path"] = r"d:\robocode\ros2_robot_arm\ros2_ws\src\dofbot_garbage_yolov5\dofbot_garbage_yolov5\config\offset.txt"
    else:  # Linux/Ubuntu
        # Ubuntuç¯å¢ƒ - ä»…CPU
        config["model_path_pt"] = "/home/HwHiAiUser/robocode_ld3/mindyolo-master/yolov8s.pt"
        config["offset_path"] = "/home/HwHiAiUser/robocode_ld3/ros2_robot_arm/ros2_ws/src/dofbot_garbage_yolov5/dofbot_garbage_yolov5/config/offset.txt"
    
    logger.info("\n" + "="*70)
    logger.info("ğŸ¯ ç³»ç»Ÿå¯åŠ¨ä¿¡æ¯")
    logger.info("="*70)
    logger.info(f"ğŸ’» æ“ä½œç³»ç»Ÿ: {platform.system()}")
    logger.info(f"ğŸ“¦ NPUæ¨¡å‹: {config['model_path_mindir'] or 'æœªé…ç½®'}")
    logger.info(f"ğŸ“¦ CPUæ¨¡å‹: {config['model_path_pt'] or 'è‡ªåŠ¨ä¸‹è½½'}")
    logger.info(f"ğŸ¯ è®¾å¤‡æ¨¡å¼: {config['device']} (ä¼˜å…ˆNPU)")
    logger.info(f"ğŸ¯ ç›®æ ‡ç‰©å“: è‹¹æœ/æ©˜å­/æ¯å­/ç“¶å­")
    logger.info("="*70 + "\n")
    
    # åˆ›å»ºç³»ç»Ÿå®ä¾‹
    system = VoiceGuidedRobotSystem(config)
    
    # è¿è¡Œæ¨¡å¼é€‰æ‹©
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--mode", choices=["once", "continuous", "vision_only"], default="vision_only",
                       help="è¿è¡Œæ¨¡å¼: once(å•æ¬¡) æˆ– continuous(æŒç»­) æˆ– vision_only(ä»…è§†è§‰)")
    parser.add_argument("--no-voice", action="store_true", help="ç¦ç”¨è¯­éŸ³è¯†åˆ«")
    parser.add_argument("--no-llm", action="store_true", help="ç¦ç”¨LLMè§£æ")
    args = parser.parse_args()
    
    if args.mode == "once":
        system.run_once(enable_voice=not args.no_voice, enable_llm=not args.no_llm)
    elif args.mode == "vision_only":
        logger.info("ğŸ‘ï¸ ä»…è§†è§‰æ£€æµ‹æ¨¡å¼ (æ— è¯­éŸ³/LLM)")
        system.run_once(enable_voice=False, enable_llm=False)
    else:
        system.run_continuous()


if __name__ == "__main__":
    main()
