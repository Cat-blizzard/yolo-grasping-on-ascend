import subprocess
import re
import ast
import LLMæ„å›¾è¯†åˆ« as LLM
import test_voice as RV
import mindspore as ms
# ========== å¯é…ç½®å‚æ•° ==========
IMAGE_PATH = "/home/HwHiAiUser/mindyolo-master/image17112/test.jpg"
CONFIG_PATH = "/home/HwHiAiUser/mindyolo-master/configs/yolov8/yolov8s.yaml"
WEIGHT_PATH = "/home/HwHiAiUser/mindyolo-master/yolov8s.ckpt"
DEVICE_PATH = "/dev/video0"
RESOLUTION = "1280x720"

# ========== COCO ç±»åˆ«æ˜ å°„è¡¨ï¼ˆIDâ†’åç§°ï¼‰ ==========
COCO_NAMES = [
    'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',
    'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',
    'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
    'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',
    'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
    'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',
    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',
    'hair drier', 'toothbrush'
]

# åå‘æ˜ å°„ï¼šåç§°â†’ID
COCO_NAME_TO_ID = {name: i for i, name in enumerate(COCO_NAMES)}

# ========== 1ï¸âƒ£ æ‹ç…§ ==========
def capture_image():
    """è°ƒç”¨ fswebcam æ‹ç…§"""
    cmd = ["fswebcam", "-d", DEVICE_PATH, "-r", RESOLUTION, IMAGE_PATH]
    print(f"[INFO] æ‹ç…§å‘½ä»¤: {' '.join(cmd)}")
    result = subprocess.run(cmd, capture_output=True, text=True)
    if result.returncode != 0:
        raise RuntimeError(f"âŒ æ‹ç…§å¤±è´¥: {result.stderr}")
    print("[INFO] æ‹ç…§å®Œæˆ âœ…")

# ========== 2ï¸âƒ£ è°ƒç”¨é¢„æµ‹è„šæœ¬ ==========
def run_prediction():
    """è°ƒç”¨ MindYOLO çš„ predict.py è¿›è¡Œæ¨ç†"""
    cmd = [
        "python3", "/home/HwHiAiUser/mindyolo-master/predict_1.py",
        "--config", CONFIG_PATH,
        "--weight", WEIGHT_PATH,
        "--image_path", IMAGE_PATH,
    ]
    print(f"[INFO] æ¨ç†å‘½ä»¤: {' '.join(cmd)}")
    result = subprocess.run(cmd, capture_output=True, text=True)
    if result.returncode != 0:
        print(result.stderr)
        raise RuntimeError("âŒ æ¨ç†æ‰§è¡Œå¤±è´¥")
    print("[INFO] æ¨ç†å®Œæˆ âœ…")
    return result.stdout

# ========== 3ï¸âƒ£ è§£æè¾“å‡º ==========
def parse_labels(output_text):
    """ä» predict.py è¾“å‡ºä¸­æå–è¯†åˆ«æ ‡ç­¾"""
    pattern = r"Predict result is:\s*(\{.*\})"
    match = re.search(pattern, output_text)
    if not match:
        raise ValueError("æœªåœ¨è¾“å‡ºä¸­æ‰¾åˆ°è¯†åˆ«ç»“æœã€‚")

    result_dict = ast.literal_eval(match.group(1))
    if not result_dict["category_id"]:
        print("âš ï¸ æœªæ£€æµ‹åˆ°ä»»ä½•ç‰©ä½“ã€‚")
        return {}

    detected = {}
    for cid, bbox, score in zip(result_dict["category_id"], result_dict["bbox"], result_dict["score"]):
        name = COCO_NAMES[cid]
        detected[name] = {"id": cid, "bbox": bbox, "score": score}

    print("\nâœ… è¯†åˆ«ç»“æœ:")
    for k, v in detected.items():
        print(f" - {k:<15} (score={v['score']:.2f})")
        print(detected)

    return detected

# ========== 4ï¸âƒ£ ç»¼åˆæ£€æµ‹æµç¨‹ ==========
def detect():
    try:
        capture_image()
        output = run_prediction()
        detected_objects = parse_labels(output)
        print("[INFO] è¯†åˆ«æµç¨‹å®Œæˆ âœ…")
        return detected_objects
    except Exception as e:
        print(f"[ERROR] {e}")
        return {}

# ========== 5ï¸âƒ£ ä¸»ç¨‹åºé€»è¾‘ ==========
def main():
    print("[è®¾å¤‡ç±»å‹]", ms.context.get_context("device_target"))
    print("[æ¨¡å¼]", ms.context.get_context("mode"))
    detected_objects = detect()  # { 'dog': {...}, 'bottle': {...} }
    print('è¯†åˆ«å®Œæˆï¼Œç­‰å¾…è¯­éŸ³æŒ‡ä»¤...')

    voice_text = RV.asr_recognize()  # è¯­éŸ³è¯†åˆ«ç»“æœæ–‡æœ¬
    print(f"[ğŸ¤ è¯­éŸ³è¯†åˆ«ç»“æœ]: {voice_text}")

    target = LLM.target_objects(voice_text)  # æå–è¯­ä¹‰ä¸­çš„ç›®æ ‡å¯¹è±¡åï¼Œå¦‚ "dog"
    print(f"[ğŸ¤– æ¨¡å‹è¯†åˆ«å‡ºçš„ç›®æ ‡ç‰©ä½“]: {target}")

    print(LLM.evaluate_targe_object(target, detected_objects))

if __name__ == "__main__":
    main()
